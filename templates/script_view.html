{%extends "base.html"%}
{%block content%}


<div class="px-4 py-3 my-2 text-center">
  <h1 class="display-6 fw-bold">第{{page}}問 </h1>
  <h3> 以下の文章を発音してください</h3>
  <p class="fs-5">
    {{jp_script}}
  </p>
  <p class="fs-5">
    {{en_script}}
  </p>
  <div>
    <button id="start" class="btn btn-primary btn-lg px-4 gap-3">録音開始</button>
  </div>
  <br>
  <button id="send" href="{{url_for('score')}}" class="btn btn-primary btn-lg px-4 gap-3">採点</button>
  <br>

  <br>
  <div>
    <a href="{{ url_for('index') }}" class="btn btn-primary btn-lg px-4 gap-3">Back home</a>
  </div>
</div>

<script>
  const startButton = document.getElementById('start')
  const sendButton = document.getElementById('send')
  // for audio
  let audio_sample_rate = null;
  let scriptProcessor = null;
  let audioContext = null;

  // audio data
  let audioData = [];
  let bufferSize = 1024;

  // save audio data
  var onAudioProcess = function (e) {
    var input = e.inputBuffer.getChannelData(0);
    var bufferData = new Float32Array(bufferSize);
    for (var i = 0; i < bufferSize; i++) {
      bufferData[i] = input[i];
    }

    audioData.push(bufferData);
  };

  // getusermedia
  let handleSuccess = function (stream) {
    console.log('function_handleSuccess')
    audioContext = new AudioContext();
    audio_sample_rate = audioContext.sampleRate;
    console.log(audio_sample_rate);
    scriptProcessor = audioContext.createScriptProcessor(bufferSize, 1, 1);
    var mediastreamsource = audioContext.createMediaStreamSource(stream);
    mediastreamsource.connect(scriptProcessor);
    scriptProcessor.onaudioprocess = onAudioProcess;
    scriptProcessor.connect(audioContext.destination);

    console.log('record start?');

    // when time passed without pushing the stop button
//    setTimeout(function () {
//      console.log("10 sec");
//      if (stopButton.disabled == false) {
//        saveAudio();
//        console.log("saved audio");
//      }
//    }, 10000);
  };

  // export WAV from audio float data
  let exportWAV = function (audioData) {
    console.log('function_exportWAV')
    let encodeWAV = function (samples, sampleRate) {
      let buffer = new ArrayBuffer(44 + samples.length * 2);
      let view = new DataView(buffer);

      let writeString = function (view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      };

      let floatTo16BitPCM = function (output, offset, input) {
        for (let i = 0; i < input.length; i++, offset += 2) {
          let s = Math.max(-1, Math.min(1, input[i]));
          output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
        }
      };

      writeString(view, 0, 'RIFF');  // RIFFヘッダ
      view.setUint32(4, 32 + samples.length * 2, true); // これ以降のファイルサイズ
      writeString(view, 8, 'WAVE'); // WAVEヘッダ
      writeString(view, 12, 'fmt '); // fmtチャンク
      view.setUint32(16, 16, true); // fmtチャンクのバイト数
      view.setUint16(20, 1, true); // フォーマットID
      view.setUint16(22, 1, true); // チャンネル数
      view.setUint32(24, sampleRate, true); // サンプリングレート
      view.setUint32(28, sampleRate * 2, true); // データ速度
      view.setUint16(32, 2, true); // ブロックサイズ
      view.setUint16(34, 16, true); // サンプルあたりのビット数
      writeString(view, 36, 'data'); // dataチャンク
      view.setUint32(40, samples.length * 2, true); // 波形データのバイト数
      floatTo16BitPCM(view, 44, samples); // 波形データ

      return view;
    };

    let mergeBuffers = function (audioData) {
      console.log('function_mergeBuffers')
      let sampleLength = 0;
      for (let i = 0; i < audioData.length; i++) {
        sampleLength += audioData[i].length;
      }
      let samples = new Float32Array(sampleLength);
      let sampleIdx = 0;
      for (let i = 0; i < audioData.length; i++) {
        for (let j = 0; j < audioData[i].length; j++) {
          samples[sampleIdx] = audioData[i][j];
          sampleIdx++;
        }
      }
      return samples;
    };

    let dataview = encodeWAV(mergeBuffers(audioData), audio_sample_rate);
    let audioBlob = new Blob([dataview], { type: 'audio/wav' });
    console.log("DataView:")
    console.log(dataview);
    let myURL = window.URL || window.webkitURL;
    let url = myURL.createObjectURL(audioBlob);
    console.log("URL:")
    console.log(url)

    return audioBlob;
  };

  // Start Button
  startButton.addEventListener('click', function () {
    console.log('Start Button1');
    navigator.mediaDevices.getUserMedia({ audio: true, video: false })
      .then(handleSuccess);

    //    console.log('Start Button2');
  });

  // Send Button
  sendButton.addEventListener('click', function (event) {
    console.log("Button")
    var audioBlob = exportWAV(audioData);
    var xhr = new XMLHttpRequest();
      xhr.open('POST', sendButton.getAttribute('href'), true);
      xhr.setRequestHeader('Content-Type', 'application/octet-stream');
      xhr.onload  = function () {
        if (xhr.status === 200) {
          console.log('Upload successful');
        } else {
          console.log('Upload failed');
      }
      };
      xhr.send(audioBlob);
      location.replace(sendButton.getAttribute('href'));
      window.location.href = sendButton.getAttribute('href');
  });

</script>

{% endblock %}